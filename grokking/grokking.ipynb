{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using renderer: notebook_connected\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "# Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "ipython.magic(\"load_ext autoreload\")\n",
    "ipython.magic(\"autoreload 2\")\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "print(f\"Using renderer: {pio.renderers.default}\")\n",
    "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
    "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
    "pio.templates['plotly'].layout.title.font.size = 30\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import os\n",
    "import tqdm.auto as tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from typing import List, Union, Optional\n",
    "from functools import partial\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML\n",
    "\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = utils.get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "device=\"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
    "\n",
    "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dir for model\n",
    "\n",
    "PTH_LOCATION = \"models/grokking_mod.pth\"\n",
    "os.makedirs(Path(PTH_LOCATION).parent, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 113\n",
    "train_frac = 0.30\n",
    "\n",
    "# optimizer configs\n",
    "lr = 5e-3\n",
    "wd = 1.\n",
    "betas = (0.9, 0.98)\n",
    "\n",
    "num_epochs = 35_000\n",
    "checkpoint_every = 100\n",
    "\n",
    "DATA_SEED = 598\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define task\n",
    "- define mod addition\n",
    "- define dataset and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input format: |a|b|=|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   0, 113],\n",
      "        [  0,   1, 113],\n",
      "        [  0,   2, 113],\n",
      "        [  0,   3, 113],\n",
      "        [  0,   4, 113]])\n",
      "torch.Size([12769, 3])\n",
      "torch.Size([12769])\n",
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "a_vector = einops.repeat(torch.arange(p), \"i -> (i j)\", j=p)\n",
    "b_vector = einops.repeat(torch.arange(p), \"j -> (i j)\", i=p)\n",
    "equals_vector = einops.repeat(torch.tensor(113), \" -> (i j)\", i =p, j = p)\n",
    "\n",
    "dataset = torch.stack([a_vector, b_vector, equals_vector], dim=1).to(device)\n",
    "\n",
    "print(dataset[:5])\n",
    "print(dataset.shape)\n",
    "\n",
    "labels = (dataset[:, 0] + dataset[:, 1]) % p\n",
    "print(labels.shape)\n",
    "print(labels[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 21,  31, 113],\n",
      "        [ 30,  98, 113],\n",
      "        [ 47,  10, 113],\n",
      "        [ 86,  21, 113],\n",
      "        [ 99,  83, 113]])\n",
      "tensor([ 52,  15,  57, 107,  69])\n",
      "torch.Size([3830, 3])\n",
      "tensor([[ 43,  40, 113],\n",
      "        [ 31,  42, 113],\n",
      "        [ 39,  63, 113],\n",
      "        [ 35,  61, 113],\n",
      "        [112, 102, 113]])\n",
      "tensor([ 83,  73, 102,  96, 101])\n",
      "torch.Size([8939, 3])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(DATA_SEED)\n",
    "\n",
    "indices = torch.randperm(p*p)\n",
    "cutoff = int(p*p*train_frac)\n",
    "\n",
    "train_indices = indices[:cutoff]\n",
    "test_indices = indices[cutoff:]\n",
    "\n",
    "train_data = dataset[train_indices]\n",
    "train_labels = labels[train_indices]\n",
    "test_data = dataset[test_indices]\n",
    "test_labels = labels[test_indices]\n",
    "\n",
    "print(train_data[:5])\n",
    "print(train_labels[:5])\n",
    "print(train_data.shape)\n",
    "print(test_data[:5])\n",
    "print(test_labels[:5])\n",
    "print(test_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = HookedTransformerConfig(\n",
    "    n_layers = 1,\n",
    "    n_heads = 4,\n",
    "    d_model = 128,\n",
    "    d_head = 32,\n",
    "    d_mlp = 512,\n",
    "    act_fn = \"gelu\",\n",
    "    normalization_type=None,\n",
    "    d_vocab = p+1,\n",
    "    d_vocab_out=p,\n",
    "    n_ctx=3,\n",
    "    init_weights=True,\n",
    "    device=\"cpu\",\n",
    "    seed=999\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HookedTransformer(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable biases\n",
    "for name, param in model.named_parameters():\n",
    "    if \"b_\" in name:\n",
    "        param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizer + loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd, betas=betas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.7334, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
      "tensor(4.7312, dtype=torch.float64, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def loss_fn(logits, labels):\n",
    "    if len(logits.shape) == 3:\n",
    "        logits = logits[:, -1]\n",
    "        # print(logits.shape)\n",
    "    logits = logits.to(torch.float64)\n",
    "    log_probs = logits.log_softmax(dim=-1)\n",
    "    correct_log_probs = log_probs.gather(dim=-1, index=labels[:, None])[:, 0]\n",
    "    return -correct_log_probs.mean()\n",
    "\n",
    "train_logits = model(train_data)\n",
    "train_loss = loss_fn(train_logits, train_labels)\n",
    "print(train_loss)\n",
    "test_logits = model(test_data)\n",
    "test_loss = loss_fn(test_logits, test_labels)\n",
    "print(test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.727387818712341\n"
     ]
    }
   ],
   "source": [
    "# uniform loss at beginning\n",
    "print(np.log(p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "model_checkpoints = []\n",
    "checkpoint_epochs = []\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    train_logits = model(train_data)\n",
    "    train_loss = loss_fn(train_logits, train_labels)\n",
    "    train_loss.backward()\n",
    "    train_losses.append(train_loss.item())\n",
    "    with torch.inference_mode():\n",
    "        test_logits = model(test_data)\n",
    "        test_loss = loss_fn(test_logits, test_labels)\n",
    "        test_losses.append(test_loss.item())\n",
    "    if (epoch+1) % checkpoint_every == 0:\n",
    "        checkpoint_epochs.append(epoch)\n",
    "        model_checkpoints.append(copy.deepcopy(model.state_dict()))\n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {train_loss.item()} | Test Loss: {test_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
